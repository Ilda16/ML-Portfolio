{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Stacking Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will:\n",
    "\n",
    "1. Load the Airbnb \"listings\" data set.\n",
    "2. Use the stacking ensemble method to train four regressors.\n",
    "3. Train and evaluate the same four individual regressors.\n",
    "4. Compare the performance of the stacked ensemble model to that of the individual models.\n",
    "\n",
    "**<font color='red'>Note: Some of the code cells in this notebook may take a while to run.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "We will work with a preprocessed version of the Airbnb NYC \"listings\" data set. \n",
    "\n",
    "<b>Task</b>: In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`.\n",
    "\n",
    "You will be working with the file named \"airbnb_readytofit.csv.gz\" that is located in a folder named \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>...</th>\n",
       "      <th>n_host_verifications</th>\n",
       "      <th>neighbourhood_group_cleansed_Bronx</th>\n",
       "      <th>neighbourhood_group_cleansed_Brooklyn</th>\n",
       "      <th>neighbourhood_group_cleansed_Manhattan</th>\n",
       "      <th>neighbourhood_group_cleansed_Queens</th>\n",
       "      <th>neighbourhood_group_cleansed_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.578829</td>\n",
       "      <td>-2.845589</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.888373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.685756</td>\n",
       "      <td>-0.430024</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>-2.473964</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.605041</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.069535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>1.010024</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.470102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.054002</td>\n",
       "      <td>-0.066308</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_has_profile_pic  host_identity_verified  \\\n",
       "0              False                  True                    True   \n",
       "1              False                  True                    True   \n",
       "2              False                  True                    True   \n",
       "3              False                  True                   False   \n",
       "4              False                  True                    True   \n",
       "\n",
       "   has_availability  instant_bookable  host_response_rate  \\\n",
       "0              True             False           -0.578829   \n",
       "1              True             False           -4.685756   \n",
       "2              True             False            0.578052   \n",
       "3              True             False            0.578052   \n",
       "4              True             False           -0.054002   \n",
       "\n",
       "   host_acceptance_rate  host_listings_count  host_total_listings_count  \\\n",
       "0             -2.845589            -0.054298                  -0.054298   \n",
       "1             -0.430024            -0.112284                  -0.112284   \n",
       "2             -2.473964            -0.112284                  -0.112284   \n",
       "3              1.010024            -0.112284                  -0.112284   \n",
       "4             -0.066308            -0.112284                  -0.112284   \n",
       "\n",
       "   accommodates  ...  n_host_verifications  \\\n",
       "0     -1.007673  ...              1.888373   \n",
       "1      0.067470  ...              0.409419   \n",
       "2      0.605041  ...             -1.069535   \n",
       "3     -0.470102  ...             -0.576550   \n",
       "4     -1.007673  ...              0.902404   \n",
       "\n",
       "   neighbourhood_group_cleansed_Bronx  neighbourhood_group_cleansed_Brooklyn  \\\n",
       "0                                 0.0                                    0.0   \n",
       "1                                 0.0                                    1.0   \n",
       "2                                 0.0                                    1.0   \n",
       "3                                 0.0                                    0.0   \n",
       "4                                 0.0                                    0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Manhattan  \\\n",
       "0                                     1.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     1.0   \n",
       "4                                     1.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Queens  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Staten Island  room_type_Entire home/apt  \\\n",
       "0                                         0.0                        1.0   \n",
       "1                                         0.0                        1.0   \n",
       "2                                         0.0                        1.0   \n",
       "3                                         0.0                        0.0   \n",
       "4                                         0.0                        0.0   \n",
       "\n",
       "   room_type_Hotel room  room_type_Private room  room_type_Shared room  \n",
       "0                   0.0                     0.0                    0.0  \n",
       "1                   0.0                     0.0                    0.0  \n",
       "2                   0.0                     0.0                    0.0  \n",
       "3                   0.0                     1.0                    0.0  \n",
       "4                   0.0                     1.0                    0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "file_path = 'data/airbnb_readytofit.csv.gz'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we mostly focused on classification problems. For this exercise, you will focus on a regression problem and predict a continuous outcome.\n",
    "\n",
    "Your model will predict the price of a listing; the label is going to be 'price'.\n",
    "\n",
    "### Create Labeled Examples \n",
    "\n",
    "<b>Task</b>: Create labeled examples from DataFrame `df`. \n",
    "In the code cell below carry out the following steps:\n",
    "\n",
    "* Get the `price` column from DataFrame `df` and assign it to the variable `y`. This will be our label.\n",
    "* Get all other columns from DataFrame `df` and assign them to the variable `X`. These will be our features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "y = df['price']\n",
    "\n",
    "X = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Labeled Examples Into Training and Test Sets\n",
    "\n",
    "<b>Task</b>: In the code cell below, create training and test sets out of the labeled examples. \n",
    "\n",
    "1. Use scikit-learn's `train_test_split()` function to create the data sets.\n",
    "\n",
    "2. Specify:\n",
    "    * A test set that is 30 percent of the size of the data set.\n",
    "    * A seed value of '1234'. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Use the Stacking Ensemble Method to Train Four Regression Models and Evaluate the Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `StackingRegressor` class. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html).\n",
    "\n",
    "First let's import `StackingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, we will try to use four models jointly. In the code cell below, we creates a list of tuples, each consisting of a scikit-learn model function and the corresponding shorthand name that we choose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"DT\", DecisionTreeRegressor()),\n",
    "              (\"RF\", RandomForestRegressor()),\n",
    "              (\"GBDT\", GradientBoostingRegressor()),\n",
    "              (\"LR\", LinearRegression())\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Call `StackingRegressor()` with the following parameters:\n",
    "\n",
    "1. Assign the list `estimators` to the parameter `estimators`.\n",
    "2. Specify a 5-fold cross-validation using the parameter `cv`.\n",
    "3. Use the parameter 'passthrough=False'. \n",
    "\n",
    "Assign the results to the variable `stacking_model`.\n",
    "\n",
    "As you read up on the definition of the `StackingRegressor` class, you will notice that by default, the results of each model are combined using a ridge regression (a \"final regressor\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "stacking_model = StackingRegressor(estimators, cv = 5, passthrough = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and evaluate this ensemble model using cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Use scikit-learn's `cross_val_score()` function on the `stacking_model` model to obtain the 3-fold cross-validation RMSE scores. In the code cell below, perform the following steps:\n",
    "\n",
    "1. Call the function with the following arguments:\n",
    "\n",
    "    1. your model object \n",
    "    2. your training data \n",
    "    3. specify the number of folds \n",
    "    4. specify the \"scoring method\": `scoring = 'neg_root_mean_squared_error'`\n",
    "\n",
    "2. Compute the average RMSE score returned by the 3-fold cross-validation and save the result to `rmse_avg`(Recall that specifying `neg_root_mean_squared_error` will result in negative RMSE values, so you have to multiply each value by -1 to obtain the RMSE scores before obtaining the average RMSE).\n",
    "\n",
    "<b>Note</b>: This may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Cross-Validation...\n",
      "End\n",
      "average score: 0.6393061564358624\n"
     ]
    }
   ],
   "source": [
    "print('Performing Cross-Validation...')\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "score = cross_val_score(stacking_model, X_train, y_train, cv = 3, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "rmse_avg = (score*-1).mean()\n",
    "\n",
    "print('End')\n",
    "print('average score: {}'.format(rmse_avg))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: \n",
    "1. Does the stacking model perform well? <br>\n",
    "2. Which hyperparameters were used for each one of the models in the stack?<br>\n",
    "\n",
    "Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your findings here.>\n",
    "\n",
    "1.) My model score is decent, I believe that my model is nor good/bad, its pretty close to 1.0 but still far from perfect.\n",
    "\n",
    "2.)The hyperparameters used in each one of the models in the stack were: CV is used for cross validation, it will split the data into folds,,Estimators are used as predictions for features for training the meta-regressor ,, The parameter 'Passthrough' determines whether to use the original features along with the predictions from the base models when training the meta-regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Improve the Performance of the Ensemble Model\n",
    "\n",
    "Assume that you decided to further improve your model by tuning a few of the hyperparameters and finding the best ones. Do not run the code cell below, but simply analyze the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params = {\n",
    "    \"DT__max_depth\": [2, 4, 8],\n",
    "    \"GBDT__n_estimators\":[100,300]\n",
    "    \n",
    "}\n",
    "\n",
    "stack_grid = GridSearchCV(stacking, params, cv=3, verbose=4, scoring='neg_root_mean_squared_error', refit=True, n_jobs=-1)\n",
    "stack_grid.fit(X_train, y_train)\n",
    "print(stack_grid.best_params_)\n",
    "rf_grid.cv_results_['mean_test_score']\n",
    "\n",
    "\n",
    "print(\"best parameters:\", rf_grid.best_params_)\n",
    "\n",
    "rmse_stack_cv = -1*rf_grid.best_score_\n",
    "print(\"[STACK] RMSE for the best model is : {:.2f}\".format(rmse_stack_cv))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above is computationally costly (you are welcome to do so on your own time as an ungraded activity). For this lab, we will simply give away the resulting values of the best hyperparameters:<br>\n",
    "```{'DT__max_depth': 8, 'GBDT__n_estimators': 100}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create a new version of the 'estimators' list. You will use the same four regressors, but this time, you will pass the `max_depth` value above to the decision tree model, and the `n_estimators` value above to the gradient boosted decision tree. Save the estimators list to the variable `estimators_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "estimators_best = [(\"DT\", DecisionTreeRegressor(max_depth = 8)),\n",
    "              (\"RF\", RandomForestRegressor()),\n",
    "              (\"GBDT\", GradientBoostingRegressor(n_estimators = 100)),\n",
    "              (\"LR\", LinearRegression())\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create a new `StackingRegressor` object with `estimators_best`. Name the model object `stacking_best_model`. Fit `stacking_best_model` to the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement Stacking...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Implement Stacking...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "stacking_best_model = StackingRegressor(estimators = estimators_best, cv = 5, passthrough = False)\n",
    "\n",
    "stacking_best_model.fit(X_train,y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your ensemble model `stacking_best_model` on the test set (`X_test`). Save the result to the variable `stacking_best_pred`. Evaluate the results by computing the RMSE and R2 score. Save the results to the variables `rmse` and `r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.6189394134426471\n",
      "R2: 0.6371512560328931\n"
     ]
    }
   ],
   "source": [
    "# 1. Use predict() to test use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "stacking_best_pred = stacking_best_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "rmse = mean_squared_error(y_test, stacking_best_pred, squared = False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "r2 = r2_score(y_test, stacking_best_pred)\n",
    "           \n",
    "print('Root Mean Squared Error: {0}'.format(rmse))\n",
    "print('R2: {0}'.format(r2))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Fit and Evaluate Individual Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Fit and Evaluate a Linear Regression\n",
    "\n",
    "<b>Task:</b> Complete the code below to fit and evaluate a linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.7449320705359715\n",
      "[LR] R2: 0.4743911252247154\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the LinearRegression model object and assign it to variable 'lr_model'\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Fit the model to the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Use the fitted model to make predictions on the test data and save the results to variable 'y_lr_pred'\n",
    "y_lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# 4. Compute the RMSE and R2 scores using the predicted values and true target labels\n",
    "lr_rmse = mean_squared_error(y_test, y_lr_pred, squared=False)\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Fit and Evaluate a Decision Tree \n",
    "\n",
    "Let's assume you already performed a grid search to find the best model hyperparameters for your decision tree. (We are omitting this step to save computation time.) The best values are: `max_depth=8`, and `min_samples_leaf = 50`. You will train a decision tree with these hyperparameter values.\n",
    "\n",
    "<b>Task:</b> Complete the code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] Root Mean Squared Error: 0.7354145220750559\n",
      "[DT] R2: 0.4877361028893348\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the DecisionTreeRegressor model object using the hyperparameter values and assign it to the variable 'dt_model'\n",
    "dt_model = DecisionTreeRegressor(max_depth=8, min_samples_leaf=50)\n",
    "\n",
    "# 2. Fit the model to the training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Use the fitted model to make predictions on the test data and save the results to variable 'y_dt_pred'\n",
    "y_dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "# 4. Compute the RMSE and R2 scores using the predicted values and true target labels\n",
    "dt_rmse = mean_squared_error(y_test, y_dt_pred, squared=False)\n",
    "dt_r2 = r2_score(y_test, y_dt_pred)\n",
    "\n",
    "print('[DT] Root Mean Squared Error: {0}'.format(dt_rmse))\n",
    "print('[DT] R2: {0}'.format(dt_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Fit and Evaluate a Gradient Boosted Decision Tree \n",
    "\n",
    "Let's assume you already performed a grid search to find the best model hyperparameters for your gradient boosted decision tree. (We are omitting this step to save computation time.) The best values are: `max_depth=2`, and `n_estimators = 300`. You will train a GBDT with these hyperparameter values.\n",
    "\n",
    "<b>Task</b>: Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n",
      "[GBDT] Root Mean Squared Error: 0.660690005519731\n",
      "[GBDT] R2: 0.5865482634833248\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...')\n",
    "\n",
    "# 1. Create the GradientBoostingRegressor model object below and assign to variable 'gbdt_model'\n",
    "gbdt_model = GradientBoostingRegressor(max_depth=2, n_estimators=300)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Call predict() to use the fitted model to make predictions on the test data. Save the results to variable 'y_gbdt_pred'\n",
    "y_gbdt_pred = gbdt_model.predict(X_test)\n",
    "\n",
    "# 4. Compute the RMSE and R2 (on y_test and y_gbdt_pred) and save the results to gbdt_rmse and gbdt_r2\n",
    "gbdt_rmse = mean_squared_error(y_test, y_gbdt_pred, squared=False)\n",
    "gbdt_r2 = r2_score(y_test, y_gbdt_pred)\n",
    "\n",
    "print('End')\n",
    "\n",
    "print('[GBDT] Root Mean Squared Error: {0}'.format(gbdt_rmse))\n",
    "print('[GBDT] R2: {0}'.format(gbdt_r2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Fit and Evaluate  a Random Forest\n",
    "\n",
    "Let's assume you already performed a grid search to find the best model hyperparameters for your random forest model. (We are omitting this step to save computation time.) The best values are: `max_depth=32`, and `n_estimators = 300`. \n",
    "You will train a random forest with these hyperparameter values.\n",
    "\n",
    "<b>Task</b>: Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...')\n",
    "\n",
    "# 1. Create the RandomForestRegressor model object below and assign to variable 'rf_model'\n",
    "rf_model = RandomForestRegressor(max_depth=32, n_estimators = 300)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Call predict() to use the fitted model to make predictions on the test data. Save the results to variable 'y_rf_pred'\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "#4. Compute the RMSE for the Random Forest model\n",
    "rf_rmse = mean_squared_error(y_test, y_rf_pred, squared = False)\n",
    "\n",
    "# 5. Compute the R2 score for the Random Forest model\n",
    "rf_r2 = r2_score(y_test, y_rf_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Visualize Model Performance\n",
    "\n",
    "The code cell below will plot the RMSE and R2 score for the stacked ensemble model and each regressor. \n",
    "\n",
    "<b>Task:</b> Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_Results = [rmse, lr_rmse, dt_rmse, gbdt_rmse, rf_rmse]\n",
    "R2_Results = [r2, lr_r2, dt_r2, gbdt_r2, rf_r2]\n",
    "\n",
    "rg = np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "# 1. Create bar plot with RMSE results\n",
    "plt.bar(rg, RMSE_Results, width, label='RMSE')\n",
    "\n",
    "# 2. Create bar plot with R2 results\n",
    "plt.bar(rg + width, R2_Results, width, label='R2')\n",
    "\n",
    "# 3. Call plt.xticks() to add labels under the bars indicating which model the pair of RMSE and R2 bars correspond to\n",
    "model_names = ['Stacked Ensemble', 'Linear Regression', 'Decision Tree', 'Gradient Boosting', 'Random Forest']\n",
    "plt.xticks(rg + width / 2, model_names)\n",
    "\n",
    "# 4. Label the x and y axis of the plot: the x-axis should be labeled \"Models\" and the y-axis should be labeled \"RMSE and R2\"\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE and R2')\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Compare the performance of the stacking model with the individual models. Is the stacking model performing better?\n",
    "Now that you are familiar with the Airbnb data, think about how a regression for price could be improved. What would you change, either at the feature engineering stage, or in the model selection, or at the stage of hyperparameter tuning?\n",
    "Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your findings here.>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
